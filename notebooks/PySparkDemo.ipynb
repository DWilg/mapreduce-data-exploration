{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce71904",
   "metadata": {},
   "source": [
    "# PySpark Demo – MapReduce & Agregacje\n",
    "Ten notebook pokazuje alternatywę Spark dla lokalnych zadań MapReduce: word count oraz agregację transakcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "spark = (SparkSession.builder.appName('PySparkDemo').getOrCreate())\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ac6ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_PATH = os.path.join('..', 'data', 'transactions_sample.csv')\n",
    "df = (spark.read.option('header', True).option('inferSchema', True).csv(DATA_PATH))\n",
    "df.printSchema()\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3374a59b",
   "metadata": {},
   "source": [
    "## Word Count (kolumna category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aed460",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_rdd = df.select('category').na.fill('').rdd.map(lambda r: r[0])\n",
    "tokens = (category_rdd\n",
    "  .flatMap(lambda v: v.replace(',', ' ').replace('.', ' ').split())\n",
    "  .filter(lambda w: w)\n",
    "  .map(lambda w: (w.lower(), 1))\n",
    "  .reduceByKey(lambda a,b: a+b))\n",
    "top_wc = tokens.takeOrdered(10, key=lambda kv: -kv[1])\n",
    "top_wc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd17d46",
   "metadata": {},
   "source": [
    "## Agregacja transakcji (DataFrame API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a885f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = (df.groupBy('category')\n",
    "          .agg(F.count('*').alias('count'),\n",
    "               F.sum('amount').alias('total'),\n",
    "               F.avg('amount').alias('avg'))\n",
    "          .orderBy(F.col('total').desc()))\n",
    "agg.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de98cc44",
   "metadata": {},
   "source": [
    "## Zapis do Parquet (opcjonalnie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_OUT = os.path.join('..', 'data', 'processed', 'transactions.parquet')\n",
    "os.makedirs(os.path.dirname(PARQUET_OUT), exist_ok=True)\n",
    "df.write.mode('overwrite').parquet(PARQUET_OUT)\n",
    "print('Zapisano:', PARQUET_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924c23a",
   "metadata": {},
   "source": [
    "## Porównanie: lokalny silnik vs Spark (opis)\n",
    "Lokalny silnik MapReduce (multiprocessing) działa szybko na małych danych. Spark daje skalowalność, API DataFrame i integrację z MLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4118b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
